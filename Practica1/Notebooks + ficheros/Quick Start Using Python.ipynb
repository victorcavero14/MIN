{"cells":[{"cell_type":"markdown","source":["## Quick Start Using Python\n* Using a Databricks notebook to showcase DataFrame operations using Python\n* Reference http://spark.apache.org/docs/latest/quick-start.html"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"111599a2-b0d0-4f22-b1ec-c7e83ab20bc2"}}},{"cell_type":"code","source":["# Take a look at the file system\ndisplay(dbutils.fs.ls(\"/databricks-datasets/samples/docs/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"e11e51b7-412f-42d0-af28-5bf3637404c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/databricks-datasets/samples/docs/README.md","README.md",3137]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/samples/docs/README.md</td><td>README.md</td><td>3137</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["DataFrames have ***transformations***, which return pointers to new DataFrames, and ***actions***, which return values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"b52cc6c7-b75f-4617-9ed9-db178f9afc1c"}}},{"cell_type":"code","source":["# transformation\ntextFile = spark.read.text(\"/databricks-datasets/samples/docs/README.md\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"f1073796-a13c-4db6-bc9f-62df4fff689a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# action\ntextFile.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"93f6bbeb-5739-4033-8757-b47ed753eb6f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[3]: 65</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: 65</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Output the first line from the text file\ntextFile.first()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"a761d0fa-283c-410e-9a7f-417f3996fc4b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: Row(value=&#39;Welcome to the Spark documentation!&#39;)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: Row(value=&#39;Welcome to the Spark documentation!&#39;)</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now we're using a filter ***transformation*** to return a new DataFrame with a subset of the items in the file."],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"bdb87eaf-fd35-4f6d-a7c5-79ad9ba6aaba"}}},{"cell_type":"code","source":["# Filter all of the lines within the DataFrame\nlinesWithSpark = textFile.filter(textFile.value.contains(\"Spark\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"b63ce36e-5ded-41fc-8ef7-f1a569e9dc12"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"linesWithSpark","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"value","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2381974877562553&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Filter all of the lines wihtin the RDD and output the first five rows</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>linesWithSpark <span class=\"ansiyellow\">=</span> textFile<span class=\"ansiyellow\">.</span>filter<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> line<span class=\"ansiyellow\">:</span> <span class=\"ansiblue\">&quot;Spark&quot;</span> <span class=\"ansigreen\">in</span> line<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.pyc</span> in <span class=\"ansicyan\">filter</span><span class=\"ansiblue\">(self, condition)</span>\n<span class=\"ansigreen\">   1260</span>             jdf <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>filter<span class=\"ansiyellow\">(</span>condition<span class=\"ansiyellow\">.</span>_jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1261</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1262</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;condition should be string or Column&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1263</span>         <span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>jdf<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>sql_ctx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1264</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: condition should be string or Column</div>","errorSummary":"<span class=\"ansired\">TypeError</span>: condition should be string or Column","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2381974877562553&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Filter all of the lines wihtin the RDD and output the first five rows</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>linesWithSpark <span class=\"ansiyellow\">=</span> textFile<span class=\"ansiyellow\">.</span>filter<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> line<span class=\"ansiyellow\">:</span> <span class=\"ansiblue\">&quot;Spark&quot;</span> <span class=\"ansigreen\">in</span> line<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.pyc</span> in <span class=\"ansicyan\">filter</span><span class=\"ansiblue\">(self, condition)</span>\n<span class=\"ansigreen\">   1260</span>             jdf <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>filter<span class=\"ansiyellow\">(</span>condition<span class=\"ansiyellow\">.</span>_jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1261</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1262</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;condition should be string or Column&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1263</span>         <span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>jdf<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>sql_ctx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1264</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: condition should be string or Column</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Notice that this completes quickly because it is a transformation but lacks any action.  \n* But when performing the actions below (e.g. count, take) then you will see the executions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"51f55c76-cb46-4615-a2d4-a9ec4b4f5f3a"}}},{"cell_type":"code","source":["# Perform a count (action) \nlinesWithSpark.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"db98051c-4a74-4654-8b42-5fcd6c005ae3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>12\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>12\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"Command skipped","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Output the first five rows\nlinesWithSpark.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":null,"showTitle":false,"inputWidgets":{},"nuid":"9e62b92b-686d-4e69-a9aa-9273bd9094fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\n[Row(value=u&apos;Welcome to the Spark documentation!&apos;),\n Row(value=u&apos;This readme will walk you through navigating and building the Spark documentation, which is included&apos;),\n Row(value=u&apos;here with the Spark source code. You can also find documentation specific to release versions of&apos;),\n Row(value=u&apos;Spark at http://spark.apache.org/documentation.html.&apos;),\n Row(value=u&apos;whichever version of Spark you currently have checked out of revision control.&apos;)]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\n[Row(value=u&apos;Welcome to the Spark documentation!&apos;),\n Row(value=u&apos;This readme will walk you through navigating and building the Spark documentation, which is included&apos;),\n Row(value=u&apos;here with the Spark source code. You can also find documentation specific to release versions of&apos;),\n Row(value=u&apos;Spark at http://spark.apache.org/documentation.html.&apos;),\n Row(value=u&apos;whichever version of Spark you currently have checked out of revision control.&apos;)]\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"Command skipped","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Quick Start Using Python","dashboards":[],"language":"python","widgets":{},"notebookOrigID":7757505863530}},"nbformat":4,"nbformat_minor":0}
